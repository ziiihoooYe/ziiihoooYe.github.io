<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ziiihooo.com/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ziiihooo.com/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-05-17T09:14:20+00:00</updated><id>https://ziiihooo.com/feed.xml</id><title type="html">Zihao Ye</title><subtitle></subtitle><entry><title type="html">Improving Image De-raining Models Using Reference-guided Transformers</title><link href="https://ziiihooo.com/blog/2024/derain/" rel="alternate" type="text/html" title="Improving Image De-raining Models Using Reference-guided Transformers"/><published>2024-01-10T00:00:00+00:00</published><updated>2024-01-10T00:00:00+00:00</updated><id>https://ziiihooo.com/blog/2024/derain</id><content type="html" xml:base="https://ziiihooo.com/blog/2024/derain/"><![CDATA[<script src="https://d3js.org/d3.v7.min.js"></script> <h2 id="abstract">Abstract</h2> <p>Image de-raining is a critical task in computer vision to improve visibility and enhance the robustness of outdoor vision systems. While recent advances in de-raining methods have achieved remarkable performance, the challenge remains to produce high-quality and visually pleasing de-rained results. In this paper, we present a reference-guided de-raining filter, a transformer module that enhances the de-raining results using a clean reference image as guidance. We leverage the capabilities of the proposed module to refine further the images de-rained by existing methods. We validate our method on four datasets and show that our module can improve the performance of existing prior-based, CNN-based, and transformer-based approaches.</p> <h2 id="method">Method</h2> <div class="fake-img l-page"> <figure> <picture> <img src="/assets/img/derain_pipeline.png" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Overview of the proposed reference-guided transformers for de-raining enhancement. We obtain de-rained results from de-raining baseline model. De-rained image \(\hat X_c\) , de-rained reference image \(\hat R_c\) and clean reference image \(R_c\) are input of our pipeline. Firstly, they are projected into feature space in Feature Extractor module, resulting \(P^3_{\hat X_c}\) , \(P^3_{\hat R_c}\) and \(P^3_{ X_c}\). Feature Attention module will further calculate relevance between query \(P^3_{\hat X_c}\) and key \(P^3_{\hat R_c}\). And Output useful feature \(P\) taking \(P_{R_c}\) as the value according to the hard attention map \(H\). \(P\) and soft attention map \(S\) are compensated to de-rained image \(\hat X _c\) to get the pipeline output \(\hat X_c ^{out}\) .</p> <h2 id="results">Results</h2> <p>In this section, we present results obtained on the Cityscapes-Rain <d-cite key="Cityscapes-Rain"></d-cite> and BDD100K-Rain <d-cite key="bdd100k, SyRaGAN"></d-cite> datasets, using baseline models PReNet <d-cite key="PReNet"></d-cite> and Uformer <d-cite key="Uformer"></d-cite>.</p> <div id="result_div" class="l-page"></div> <script src="/assets/js/de-rain.js"></script>]]></content><author><name>Zihao Ye</name></author><category term="machine_learning"/><summary type="html"><![CDATA[]]></summary></entry></feed>